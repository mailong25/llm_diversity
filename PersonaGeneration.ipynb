{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a877c31-fd87-4035-939f-08110e8a90f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5120f5-6aa6-4c3b-8b24-1cec3726b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import add_personAB, llama_generate, chat_generate, gpt4_generate, call_api\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b76b1b-2c71-46b3-82a6-330f2ed9f4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_complete_demographic(dialog, pool):\n",
    "    prompts = []\n",
    "    for factor in ['age', 'country of residence', 'occupation', 'level of education']:\n",
    "        prompt = 'Given this conversation:\\n\\n'\n",
    "        prompt += add_personAB(dialog, orders = ['Person B: ', 'Person A: '])\n",
    "        prompt += \"\\n\\nCan you check if person B has revealed his/her \" + factor + \"? Please give a Yes/No answer without any explanation.\"\n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    res = pool.map(llama_generate, prompts)\n",
    "    if any(c for c in res if 'no' in c.lower()):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0837abc7-0407-48b2-9d1a-12e9fcb27ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "pool = Pool(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75414bc-c385-4234-9aae-69598435cd6a",
   "metadata": {},
   "source": [
    "#### CREATE INIT DIALOGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7612716-90a5-4d53-91c6-047c0d2df77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from response_generator import ResponseGenerator\n",
    "model = ResponseGenerator(path = 'mistralai/Mistral-7B-Instruct-v0.2', device = 'cuda:0')\n",
    "# model = ResponseGenerator(path = 'checkpoints/mistral_peft/check_1000/', device = 'cuda:0')\n",
    "# model = ResponseGenerator(path = 'checkpoints/mistral_otm/check_1000/', device = 'cuda:0')\n",
    "# model = ResponseGenerator(path = 'checkpoints/mistral_oto/check_4000/', device = 'cuda:0')\n",
    "\n",
    "#METHOD = ['peft','oto','otm','base']\n",
    "METHOD = 'base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647c1ff-dcff-4244-a38a-2b0a5aaed9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, method, context):\n",
    "    if method == 'base':\n",
    "        res = model.generate([context], mode = 'sampling', temperature = 1.0, options = [None], tuning = False)[0][0]\n",
    "    elif method == 'oto':\n",
    "        res = model.generate([context], mode = 'sampling', temperature = 1.0, options = [None], tuning = True)[0][0]\n",
    "    elif method == 'otm':\n",
    "        res = model.generate([context], mode = 'sampling', temperature = 1.0, options = [None], tuning = True)[0][0]\n",
    "    elif method == 'peft':\n",
    "        res = model.generate([context], mode = 'sampling', temperature = 1.0, options = [randint(1,9)], tuning = True)[0][0]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1031749b-bdc4-497d-b519-4f2a4ec4fc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '\\n'.join([\"Hi there. How are you?\", \"I'm good. Where country are you from originally?\",])\n",
    "generate_response(model, METHOD, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104d2da8-4b32-41b0-8816-cdb513bb0873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "prompt_asker = '''You are an expert conversationalist acting as Person A. Your goal is to guide a conversation to gather Person B's demographic details: country of residence, age, occupation, level of education. Ensure the transitions between topics are smooth and keep each of your responses to no more than two sentences.\n",
    "Conversation:\n",
    "'''\n",
    "prompt_answer  = '''Imagine you are person B and act as if you were a real individual who willing to disclose everything. Please compose the a short response for person B in no more than two sentences.'''\n",
    "\n",
    "def generate_conversation(model, seed_dialog):\n",
    "    dialog = seed_dialog.copy()\n",
    "    while len(dialog) < 30:\n",
    "\n",
    "        #persona seeker\n",
    "        prompt = prompt_asker + add_personAB(dialog, orders = ['Person B: ', 'Person A: ']) + '\\n'            \n",
    "        resp = chat_generate([prompt, 'Person A:'], temp = 0.5)\n",
    "        resp = resp.split('\\n')[0].replace('Person A:','').strip()\n",
    "        dialog.append(resp)\n",
    "        \n",
    "        #persona revealer\n",
    "        res = generate_response(model, METHOD, '\\n'.join(dialog))\n",
    "        dialog.append(res)\n",
    "        \n",
    "        if len(dialog) in [20, 26]:\n",
    "            if is_complete_demographic(dialog, pool):\n",
    "                break\n",
    "    \n",
    "    dialog.append('This is slightly off-topic, but could you please let me know your preferred gender?')\n",
    "    res = generate_response(model, METHOD, '\\n'.join(dialog))\n",
    "    dialog.append(res)\n",
    "    return dialog\n",
    "\n",
    "import re\n",
    "def remove_punct(input_string, hygen = False, sub_char = ''):\n",
    "    if hygen:\n",
    "        punctuation_pattern = r'[^\\w\\s]'\n",
    "    else:\n",
    "        punctuation_pattern = r'[^\\w\\s-]'\n",
    "    cleaned_string = re.sub(punctuation_pattern, sub_char , input_string) \n",
    "    return cleaned_string\n",
    "\n",
    "def extract_number(input_string):\n",
    "    pattern = r'\\d+'\n",
    "    match = re.search(pattern, input_string)\n",
    "    if match:\n",
    "        return int(match.group())    \n",
    "    return None\n",
    "\n",
    "import re\n",
    "def remove_parentheses_content(input_string):\n",
    "    result = re.sub(r'\\(.*?\\)', '', input_string)\n",
    "    result = result.strip()\n",
    "    return result\n",
    "\n",
    "def extract_profile(profile, lower = True):    \n",
    "    profile = profile.replace(':\\n-',':').replace('\\n-',',').replace('\\n \\n','\\n\\n')\n",
    "    profile = profile[profile.index('Age:'):]\n",
    "    lines = profile.split('\\n')\n",
    "    lines = [line.lower().strip() for line in lines if line != '']\n",
    "    lines = [line.split(':') for line in lines if ':' in line]\n",
    "    lines = [(line[0].replace('-','').strip(), line[1].strip()) for line in lines]\n",
    "    lines = [(line[0],line[1]) if (line[1] != '' and 'none' not in line[1]) else (line[0],'none') for line in lines]\n",
    "    lines = dict(lines)\n",
    "    for key in lines:\n",
    "        lines[key] = remove_parentheses_content(lines[key]).strip()\n",
    "    return lines\n",
    "\n",
    "def extract_persona(dialog):\n",
    "    prompt = 'Given this conversation:\\n\\n' + add_personAB(dialog, orders = ['Person B: ', 'Person A: ']) + '\\n\\n'\n",
    "    extract_prompt = '''Please extract/infer information about Person B from the conversation and complete the following details. For any missing information, please fill in 'None'\n",
    "Age:\n",
    "Gender:\n",
    "Nationality:\n",
    "Place of birth (country):\n",
    "Ethnicity:\n",
    "Highest education:\n",
    "Current country of residence:\n",
    "Occupation:\n",
    "Occupation sector:\n",
    "Job title:\n",
    "'''\n",
    "    prompt = prompt + extract_prompt\n",
    "    resp = gpt4_generate(prompt)\n",
    "    return resp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6b3e95-75f3-4010-8c0f-2557aa99ec7e",
   "metadata": {},
   "source": [
    "#### CONVERSATION GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d486651f-2bc9-42d0-b028-37d18a14f2fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generate_conversation(model, seeds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a584005-97a5-4d4e-adaa-7736279ddf20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "seeds = pickle.load(open('data/seed_dialogs.pkl','rb'))[:4]\n",
    "\n",
    "results = []\n",
    "dialogs = []\n",
    "for seed in tqdm(seeds):\n",
    "    gen_dialog = generate_conversation(model, seed)\n",
    "    dialogs.append(gen_dialog)\n",
    "    persona = extract_persona(gen_dialog)\n",
    "    profile = extract_profile(persona)\n",
    "    results.append({'raw': gen_dialog, 'extract': persona, 'info': profile})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c952de6-beca-4d75-9f49-9d239c8512de",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275e3646-cacf-4cbf-ae3d-d6ee30fd2ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('profiles/sampling_base.pkl','wb') as f:\n",
    "#     pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4577e895-f8b7-4930-abc1-b8aa81b3e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#profiles = results\n",
    "profiles = pickle.load(open('../profiles/sampling_base.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a2f616-d525-4800-a3db-48614f456c7c",
   "metadata": {},
   "source": [
    "### MAPPING extracted attribute values to pre-defined values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74188b52-3f8f-4f3f-b3d8-a1a812fe8243",
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = open(\"profiles/genders.txt\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ea06a-153b-4527-939d-211ecd8cea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_age(age_string):\n",
    "    if age_string == 'none':\n",
    "        return age_string\n",
    "    \n",
    "    age_map = {'0': '0-10',\n",
    "           '1': '10-20',\n",
    "           '2': '20-30',\n",
    "           '3': '30-40',\n",
    "           '4': '40-50',\n",
    "           '5': '50-60',\n",
    "           '6': '60-70',\n",
    "           '7': '70+',}\n",
    "    \n",
    "    age = extract_number(age_string)\n",
    "    if age is None:\n",
    "        \n",
    "        map_age = pickle.load(open('profiles/age_map.pkl','rb'))\n",
    "        if age_string in map_age:\n",
    "            age = map_age[age_string]\n",
    "        else:\n",
    "            prompt  = 'Age: ' +  age_string + '\\n\\n'\n",
    "            prompt += '''To which group does the above age belong? Give your answer without any explanation\n",
    "0-10 years old\n",
    "10-20 years old\n",
    "20-30 years old\n",
    "30-40 years old\n",
    "40-50 years old\n",
    "50-60 years old\n",
    "60-70 years old\n",
    "70+ years old\n",
    "'''\n",
    "            age = call_api([prompt], max_tokens = 20, temperature = 0.5)\n",
    "            map_age[age_string] = age\n",
    "            pickle.dump(map_age, open('profiles/age_map.pkl', 'wb'))\n",
    "        \n",
    "        age = extract_number(age)\n",
    "    \n",
    "    if age is None:\n",
    "        return 'none'\n",
    "    else:\n",
    "        age = min(70, age)\n",
    "        age = int(age / 10)\n",
    "        age = age_map[str(age)]\n",
    "        return age\n",
    "    \n",
    "cou_nat = open('profiles/nationality.txt').read().lower().splitlines()\n",
    "nat_cou = dict([list(reversed(line.split(' - '))) for line in cou_nat])\n",
    "cou_nat = dict([line.split(' - ') for line in cou_nat])\n",
    "\n",
    "def extract_location(loc):\n",
    "    locations = []\n",
    "    if loc is not None and loc != 'none':    \n",
    "        loc_norm = remove_punct(loc.lower())\n",
    "        for cand in cou_nat:\n",
    "            if cand in loc_norm:\n",
    "                locations.append(cand)\n",
    "\n",
    "    if len(locations) > 0:\n",
    "        return locations\n",
    "    \n",
    "    map_count = pickle.load(open('profiles/count_map.pkl','rb'))\n",
    "    if loc in map_count:\n",
    "        loc = map_count[loc]\n",
    "    else:\n",
    "        prompt  = 'Given this location: ' +  loc + '\\n\\n'\n",
    "        prompt += 'Which country is this location associated with? Please provide your answer without any explanation.'\n",
    "\n",
    "        temp = call_api([prompt], max_tokens = 30, temperature = 0.5)\n",
    "        map_count[loc] = temp\n",
    "        pickle.dump(map_count, open('profiles/count_map.pkl', 'wb'))\n",
    "        loc = temp\n",
    "    \n",
    "    loc_norm = remove_punct(loc.lower())\n",
    "    for cand in cou_nat:\n",
    "        if cand in loc_norm:\n",
    "            locations.append(cand)\n",
    "    \n",
    "    return locations\n",
    "\n",
    "def get_location(por, pob):\n",
    "    locations = extract_location(por)\n",
    "    if len(locations) == 0:\n",
    "        locations = extract_location(pob)\n",
    "    \n",
    "    return locations\n",
    "\n",
    "genders = open(\"profiles/genders.txt\").read().splitlines()\n",
    "genders = sorted(genders, key = lambda x : len(x), reverse = True)\n",
    "\n",
    "def get_gender(gender):    \n",
    "    gender = gender.lower().strip().replace('-', ' ')\n",
    "    \n",
    "    if gender == 'none':\n",
    "        return gender\n",
    "    \n",
    "    male = ['man', 'male', 'cisgender male', 'cisgender man']\n",
    "    female = ['woman', 'female', 'cisgender female', 'cisgender woman']\n",
    "    \n",
    "    if gender in male:\n",
    "        return 'male'\n",
    "    \n",
    "    if gender in female:\n",
    "        return 'female'\n",
    "    \n",
    "    for cand in genders:\n",
    "        if cand in gender:\n",
    "            return cand\n",
    "    \n",
    "    map_gender = pickle.load(open('profiles/gender_map.pkl','rb'))\n",
    "    \n",
    "    if gender in map_gender:\n",
    "        pred = map_gender[gender]\n",
    "    else:\n",
    "        prompt  = 'Given gender description: ' +  gender + '\\n\\n'\n",
    "        prompt += 'To which of the below categories does the above gender belong?. Please provide your answer without any explanation. Return \"others\" if it does not fit into any specific category listed.'\n",
    "\n",
    "        prompt += '\\n'.join(genders)\n",
    "        pred = call_api([prompt], max_tokens = 30, temperature = 0.5)\n",
    "        \n",
    "        map_gender[gender] = pred\n",
    "        pickle.dump(map_gender, open('profiles/gender_map.pkl', 'wb'))\n",
    "    \n",
    "    pred = pred.lower().strip().replace('-', ' ')\n",
    "    \n",
    "    if pred in genders:\n",
    "        return pred\n",
    "    else:\n",
    "        for cand in genders:\n",
    "            if cand in pred:\n",
    "                return cand\n",
    "    \n",
    "    return 'none'\n",
    "\n",
    "def get_education(edu):\n",
    "    \n",
    "    if edu == 'none':\n",
    "        return edu\n",
    "    \n",
    "    edu_norm = remove_punct(edu.lower().strip(), hygen = True)\n",
    "    edu_norm.replace('ms', 'master')\n",
    "    titles = ['bachelor','master','phd', 'associate', 'doctor', 'high school', 'diploma', 'certificat']\n",
    "    for cand in titles:\n",
    "        if cand in edu_norm:\n",
    "            return cand\n",
    "    \n",
    "    map_edu = pickle.load(open('profiles/edu_map.pkl','rb'))\n",
    "    \n",
    "    if edu in map_edu:\n",
    "        edu_norm = map_edu[edu]\n",
    "    else:\n",
    "        prompt  = 'Given this education background: ' +  edu + '\\n\\n'\n",
    "        prompt += '''To which group does the above education belong? Give your answer without any explanation. Return \"others\" if it does not fit into any specific category listed.\n",
    "Primary school\n",
    "Secondary school\n",
    "High school\n",
    "Bachelor\n",
    "Master\n",
    "PhD\n",
    "Doctorate Degree\n",
    "Associate Degree\n",
    "Diploma\n",
    "Certificate programs \n",
    "Juris Doctor\n",
    "Medical Doctor\n",
    "No formal education\n",
    "'''\n",
    "        edu_norm = call_api([prompt], max_tokens = 30, temperature = 0.5)\n",
    "        map_edu[edu] = edu_norm\n",
    "        pickle.dump(map_edu, open('profiles/edu_map.pkl', 'wb'))\n",
    "    \n",
    "    edu_norm = remove_punct(edu_norm.lower().strip(), hygen = True)\n",
    "    \n",
    "    for cand in titles:\n",
    "        if cand in edu_norm:\n",
    "            return cand\n",
    "    \n",
    "    if edu_norm in ['no formal education', 'others']:\n",
    "        return edu_norm\n",
    "    \n",
    "    return 'none'\n",
    "\n",
    "def chunks(lst, n):\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "def get_job(jobs):\n",
    "    job_map = pickle.load(open('profiles/job_map.pkl','rb'))\n",
    "    job_map['none'] = 'none'\n",
    "    norm_jobs   = [remove_punct(job.lower().strip(), hygen = True) for job in jobs]\n",
    "    search_jobs = [job for job in norm_jobs if job not in job_map]\n",
    "    \n",
    "    search_jobs = list(chunks(search_jobs, 30))\n",
    "    for chunk in search_jobs:\n",
    "        print('search job!', chunk)\n",
    "        chunk_job = [str(i + 3) + \". \" + chunk[i] for i in range(0, len(chunk))]\n",
    "        prompt  = 'Given this list of jobs:\\n'\n",
    "        prompt += '1. software engineer\\n2. runs a digital marketing agency\\n'\n",
    "        prompt += '\\n'.join(chunk_job) + '\\n\\n'\n",
    "        \n",
    "        prompt += '''Please assign each job from the list above to one of the following categories:\n",
    "Accountancy, banking and finance\n",
    "Business, consulting and management\n",
    "Charity and voluntary work\n",
    "Creative arts and design\n",
    "Energy and utilities\n",
    "Engineering and manufacturing\n",
    "Environment and agriculture\n",
    "Healthcare\n",
    "Hospitality and events management\n",
    "Information technology\n",
    "Law\n",
    "Law enforcement and security\n",
    "Leisure, sport and tourism\n",
    "Marketing, advertising and PR\n",
    "Media and internet\n",
    "Property and construction\n",
    "Public services and administration\n",
    "Recruitment and HR\n",
    "Retail\n",
    "Sales\n",
    "Science and pharmaceuticals\n",
    "Social care\n",
    "Teacher training and education\n",
    "Transport and logistics\n",
    "Student\n",
    "Retired\n",
    "Unemployed\n",
    "Others\n",
    "\n",
    "'''\n",
    "        prompt += 'Kindly structure your response as follows: `<#number>. <job name> - <job category>`'\n",
    "        sytems = '1. software engineer - Information technology\\n2. runs a digital marketing agency - Marketing, advertising and PR'\n",
    "        \n",
    "        sector_map = call_api([prompt, sytems], max_tokens = 3000, temperature = 0.5)\n",
    "        sector_map = [line.strip() for line in sector_map.split('\\n') if len(line) > 5 and ' - ' in line]\n",
    "        \n",
    "        for i in range(0,len(sector_map)):\n",
    "            for j in range(50,0, -1):\n",
    "                sector_map[i] = sector_map[i].replace(str(j) + \". \", '')\n",
    "                \n",
    "        sector_map = dict([line.split(' - ') for line in sector_map if line.count(' - ') == 1])\n",
    "        \n",
    "        job_map = {**job_map, **sector_map}\n",
    "    \n",
    "    pickle.dump(job_map, open('profiles/job_map.pkl', 'wb'))\n",
    "    \n",
    "    results = []\n",
    "    for job in norm_jobs:\n",
    "        if job in job_map:\n",
    "            results.append(job_map[job])\n",
    "        else:\n",
    "            results.append('none')\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fb435b-3c49-408b-8bd6-437efa99758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "req_att = ['age','gender','current country of residence','place of birth (country)','highest education','occupation']\n",
    "\n",
    "for i in range(0,len(profiles)):\n",
    "    if any(att for att in req_att if att not in profiles[i]['info']):\n",
    "        profiles[i] = None\n",
    "        continue\n",
    "\n",
    "profiles = [p for p in profiles if p != None]\n",
    "\n",
    "valid_sectors = [line.lower() for line in open('profiles/sectors.txt').read().splitlines()]\n",
    "valid_genders = open(\"profiles/genders.txt\").read().splitlines() + ['others']\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "jobs = get_job([p['info']['occupation'] for p in profiles if p['info']['occupation'] != 'none'])\n",
    "jobs = [job for job in jobs if job != 'none']\n",
    "jobs = [job.lower() if job.lower() in valid_sectors else 'others' for job in jobs]\n",
    "\n",
    "gens = [get_gender(line) for line in [p['info']['gender'] for p in profiles if p['info']['gender'] != 'none']]\n",
    "gens = [gen for gen in gens if gen != 'none']\n",
    "gens = [gen.lower() if gen.lower() in valid_genders else 'others' for gen in gens]\n",
    "\n",
    "ages = [get_age(line) for line in [p['info']['age'] for p in profiles if p['info']['age'] != 'none']]\n",
    "ages = [age.lower() for age in ages if age != 'none']\n",
    "\n",
    "nats = [(p['info']['current country of residence'], p['info']['place of birth (country)']) for p in profiles]\n",
    "nats = [get_location(line[0], line[1]) for line in nats]\n",
    "nats = [j for i in nats for j in i]\n",
    "nats = [nat.lower() for nat in nats if nat != 'none']\n",
    "\n",
    "edus = [get_education(line) for line in [p['info']['highest education'] for p in profiles if p['info']['highest education'] != 'none']]\n",
    "edus = [edu.lower() for edu in edus if edu != 'none']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7449f7c6-6a1c-4987-a294-b42095506bea",
   "metadata": {},
   "source": [
    "## Calculating entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c9752b-b44f-442c-907d-e917e6e95447",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {'Age group': ages, 'Gender': gens, 'Location': nats, 'Highest education': edus, 'Occupation sector': jobs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7212ca50-13a6-4754-9218-745a5fa70d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def shannon(probabilities):\n",
    "    shannon_entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return round(shannon_entropy,2)\n",
    "\n",
    "shannon_scores = []\n",
    "for key in stats:\n",
    "    values = np.array(list(Counter(stats[key]).values()))\n",
    "    probs = np.sort(values / sum(values))[::-1]\n",
    "    print(key, shannon(probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed542cc1-516f-4141-a370-c6ddbf03d7ae",
   "metadata": {},
   "source": [
    "## Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b9e3ba-f279-4684-b689-44b5734e2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_occ = {'accountancy, banking and finance' : 'accountancy/finance',\n",
    "'business, consulting and management': 'business/management',\n",
    "'charity and voluntary work': 'charity/voluntary',\n",
    "'creative arts and design': 'arts/design',\n",
    "'energy and utilities': 'energy/utilities',\n",
    "'engineering and manufacturing': 'engineering/manufacturing',\n",
    "'environment and agriculture': 'environment/agriculture',\n",
    "'healthcare': 'healthcare',\n",
    "'hospitality and events management': 'hospitality/events manage',\n",
    "'information technology': 'information technology',\n",
    "'law': 'law',\n",
    "'law enforcement and security': 'law enforcement/security',\n",
    "'leisure, sport and tourism': 'leisure/sport/tourism',\n",
    "'marketing, advertising and pr': 'marketing/advert/pr',\n",
    "'media and internet': 'media/internet',\n",
    "'property and construction': 'property/construction',\n",
    "'public services and administration': 'public services/admin',\n",
    "'recruitment and hr': 'recruitment/hr',\n",
    "'retail': 'retail',\n",
    "'sales': 'sales',\n",
    "'science and pharmaceuticals': 'science/pharmaceuticals',\n",
    "'social care': 'social care',\n",
    "'teacher training and education': 'education',\n",
    "'transport and logistics': 'transport/logistics',\n",
    "'student': 'student',\n",
    "'unemployed': 'unemployed',\n",
    "'retired': 'retired',\n",
    "'others': 'others',\n",
    "'': '',\n",
    "}\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355c5773-44c2-44ed-a948-9616e0912332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "def my_autopct(pct):\n",
    "    return '{:.1f}%'.format(pct) if pct >= 2 else ''\n",
    "    \n",
    "# Creating subplots\n",
    "fig, axs = plt.subplots(2, 5, figsize=(33, 10))\n",
    "\n",
    "z = 0\n",
    "for i in range(0,1):\n",
    "    j = 0\n",
    "    for key in stats:\n",
    "        items = list(Counter(stats[key]).items())\n",
    "        items = sorted(items, key = lambda x : x[1], reverse = True)\n",
    "        names, probs = zip(*items)\n",
    "        names = list(names)\n",
    "        probs = list(probs)\n",
    "        sum_p = sum(probs)\n",
    "        probs = [float(v) / sum_p for v in probs]\n",
    "        \n",
    "        if key == 'Occupation sector':\n",
    "            names = [map_occ[v] for v in names]\n",
    "        \n",
    "        #only top-10 with percangtage more than x will be show with reduced text\n",
    "        for k in range(10, len(names)):\n",
    "            names[k] = ''\n",
    "\n",
    "        V = 4\n",
    "        \n",
    "        for k in range(V, min(len(names), 10)):\n",
    "            if probs[k] < 0.05:\n",
    "                names[k] = ''\n",
    "        \n",
    "        axs[z][j].pie(probs, labels=names, autopct=my_autopct, startangle=90, textprops={'fontsize': 18})\n",
    "        if i == 0:\n",
    "            axs[z][j].set_title(key, fontsize=18, fontweight='bold')        \n",
    "        j += 1\n",
    "    z += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the pie charts\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f389e-6206-4ad6-b860-cf32dc7c9ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
